In this chapter, we consider a network of quantum sensors, where each sensor is a qubit detector that ``fires,'' i.e., its state changes when an event occurs close by. 
The change in state due to the firing of a detector is given by a unitary operator which is the same for all sensors in the network. 
Such a network of detectors can be used to localize an event, using a protocol to determine the firing sensor which is presumably the one closest to the event.
The determination of the firing sensor can be posed as a {\em Quantum State Discrimination} problem which incurs a probability of error depending on the initial state and the measurement operator used. 

In this chapter, we address the problem of determining the optimal initial global state of a network of detectors that incur a minimum probability of error in determining the firing sensor. For this problem, we derive necessary and sufficient conditions for the existence of an initial state that allows for perfect discrimination, i.e., zero probability of error. 
Using insights from this result, we derive a conjectured optimal solution for the initial state, provide a pathway to prove the conjecture, and validate the conjecture empirically using multiple search heuristics that seem to perform near-optimally. 
